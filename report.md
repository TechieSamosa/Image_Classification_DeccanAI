# Image Classification Project Report

## 1. Introduction

This report details the development process, design decisions, and implementation strategies for the image classification project. The objective was to build an efficient image classification model using the CIFAR-10 dataset and deploy it as a REST API with additional bonus features such as explainability using Grad-CAM, logging, error handling, and an interactive Streamlit frontend.

## 2. Data Preprocessing & Exploratory Data Analysis

### 2.1 Data Overview
- **Dataset:** CIFAR-10
- **Classes:** 10 (Airplane, Automobile, Bird, Cat, Deer, Dog, Frog, Horse, Ship, Truck)
- **Images:** 60,000 color images (32x32 pixels) with 50,000 training images and 10,000 test images.

### 2.2 EDA Findings
- **Class Distribution:** Fairly balanced across all classes.
- **Pixel Statistics:** Images exhibit a standard range of pixel values (0 to 255). Analysis indicated the necessity for normalization and resizing to align with the input requirements of EfficientNetB0.

### 2.3 Preprocessing Steps
- **Resizing:** Images were resized to 224x224 pixels to match EfficientNetB0 input size.
- **Normalization:** Pixel values were scaled to [0, 1].
- **Data Augmentation:** Utilized rotation, horizontal flips, and zoom to enrich the training set and reduce overfitting.

The preprocessing functions are encapsulated in `src/data_preprocessing.py` and integrated into the training pipeline.

## 3. Model Architecture & Training

### 3.1 Model Selection
- **Base Model:** EfficientNetB0 was chosen for its balance between accuracy and computational efficiency.
- **Transfer Learning:** Leveraged pre-trained ImageNet weights and fine-tuned the top layers for the CIFAR-10 classification task.
- **Regularization:** Incorporated dropout layers to mitigate overfitting.

### 3.2 Training Strategy
- **Callbacks:** EarlyStopping, ReduceLROnPlateau, and ModelCheckpoint were implemented to optimize training.
- **Loss Function & Optimizer:** The model was compiled with the Adam optimizer and sparse categorical crossentropy.
- **Batch Size & Epochs:** Training was conducted with a batch size of 32 over 30 epochs with validation split to monitor generalization.

Training is orchestrated through `src/train.py` with extensive logging enabled via `src/utils.py`.

## 4. Evaluation

### 4.1 Metrics
- **Accuracy, Precision, Recall:** Assessed on the test set.
- **Confusion Matrix:** Visualized class-wise performance.
- **Classification Report:** Detailed breakdown of precision, recall, and F1-score per class.

Evaluation results, including confusion matrix and classification report, are generated by `src/evaluate.py` and saved in the `evaluation/` folder.

## 5. Model Deployment

### 5.1 API Development
- **Framework:** FastAPI was used to build a RESTful API.
- **Endpoints:**
  - `/predict`: Accepts an image file, preprocesses it, and returns the predicted class.
  - `/gradcam`: Generates a Grad-CAM visualization to explain the model's decision.
- **Security:** Implemented basic HTTP authentication via `app/auth.py`.

### 5.2 Containerization & Cloud Deployment
- **Docker:** A Dockerfile is provided to containerize the API for easy deployment.
- **Cloud:** The container can be deployed to platforms like AWS, GCP, or Render for a public API endpoint.

## 6. Bonus Enhancements

### 6.1 Grad-CAM Explainability
Implemented in `src/explainability.py`, Grad-CAM provides heatmaps that highlight important regions in the image influencing the model's prediction. This is accessible through the `/gradcam` API endpoint and integrated into the Streamlit frontend.

### 6.2 Logging & Error Handling
Comprehensive logging is implemented using Python’s `logging` module. Logs are stored in `logs/app.log` to facilitate debugging and production monitoring.

### 6.3 Streamlit Frontend
An interactive frontend built with Streamlit (`app/frontend.py`) allows users to upload images, view predictions, and generate Grad-CAM visualizations in real time. This improves accessibility and provides a visual demonstration of the model’s performance.

## 7. Conclusion & Future Work

This project successfully demonstrates a complete image classification pipeline:
- **Data Preparation:** Effective preprocessing and augmentation techniques.
- **Model Training:** Leveraging transfer learning with EfficientNetB0.
- **Deployment:** A robust API with bonus features such as Grad-CAM explainability and an interactive frontend.

### Future Enhancements
- **Model Optimization:** Experiment with alternative architectures and hyperparameters.
- **Scalability:** Explore advanced deployment options and load balancing for high traffic.
- **User Interface:** Enhance the frontend with more detailed visualizations and user feedback mechanisms.

---

This concludes the project report. For further details, refer to individual modules and notebooks in the repository.
